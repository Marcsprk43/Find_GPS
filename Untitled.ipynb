{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2891e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d06b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImages(im1, im2):\n",
    "# Convert images to grayscale\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    cv2.imshow('matches', imMatches)\n",
    "    cv2.waitKey(0)\n",
    "    #cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return im1Reg, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Read reference image\n",
    "    refFilename = \"form.jpg\"\n",
    "    print(\"Reading reference image : \", refFilename)\n",
    "    imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Read image to be aligned\n",
    "    imFilename = \"scanned-form.jpg\"\n",
    "    print(\"Reading image to align : \", imFilename)\n",
    "    im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    print(\"Aligning images ...\")\n",
    "    # Registered image will be resotred in imReg.\n",
    "    # The estimated homography will be stored in h.\n",
    "    imReg, h = alignImages(im, imReference)\n",
    "\n",
    "    # Write aligned image to disk.\n",
    "    outFilename = \"aligned.jpg\"\n",
    "    print(\"Saving aligned image : \", outFilename)\n",
    "    cv2.imshow('aligned', imReg)\n",
    "    cv2.waitKey(0)\n",
    "    #cv2.imwrite(outFilename, imReg)\n",
    "\n",
    "    # Print estimated homography\n",
    "    print(\"Estimated homography : \\n\",  h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
